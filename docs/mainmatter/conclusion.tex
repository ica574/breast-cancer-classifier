\documentclass[../main]{subfiles}

\begin{document}
\chapter{Conclusion}
This project involves an end-to-end image classification pipeline for distinguishing two classes of mammography scans using deep learning. Transfer learning is applied, with a pre-trained convolutional neural network being used for the classification of scans. The system ingests data from TFRecord files, originating from the DDSM data set. These are then pre-processed for the model to use as input. The latter is then trained, and evaluated on this data. This approach allows for the efficient use of pre-trained models, which can significantly reduce the time and resources required for training a model from scratch. 

Referring to research question \ref{rq:model_feasibility}, the models were indeed found to be feasible since they achieved high scores, particularly AUC, that exceed those of human readers. Regarding question \ref{rq:prototype_evaluation}, the acquired results, particularly F1 scores, precision, and recall scores demonstrate ways in which class balance is handled, as well as how the data set used must be balanced to improve performance. Additionally, Grad-CAM visualisations show how the model is performing, further indicating how the models make decisions, which may inform architecture changes in future versions. Finally, in relation to research question \ref{rq:clinical_integration}, which pertains to clinical integration, practical considerations were explored through a mock system architecture diagram, which denotes how the said models would be implemented in a practical setting. In this pursuit, this project has been successful, and may be further extended to meet the exigencies of a clinical setting. 

The project could be further extended to include additional features, given enough time, and resources. What was achieved in this project was limited by the time constraints, and the available resources. All the models, apart from the custom CNN baseline, achieved an AUC score exceeding 0.90, highlighting the effectiveness of transfer learning in this context, and demonstrating that machine-based detection of breast cancer could outperform human radiologists.

\section{Novelty}
The novelty of this project lies in the application of transfer learning to mammographic image classification, utilising pre-trained models to achieve high accuracy with limited data. The exploration of transformer-based architectures, such as ViT, in conjunction with CNNs is also a novel approach in this context. The project demonstrates the potential of these advanced architectures to outperform traditional CNNs in image classification tasks, particularly in the medical domain. Additionally, the technical description of a clinical workflow, including implementation details, and the potential for this project to grow into a fully fledged SaaS with horizontal scaling details, continues to further the novelty of this project.

\section{Future Work}
This project demonstrates a solid proof of concept, and a foundation for future work. The final system will require further refinement, and optimisation, as well as additional features, and functionality to make it more user-friendly, and robust.

\begin{itemize}
	\item \textbf{Model Optimisation} \textemdash\ The model can be further optimised by adjusting its architecture, and increasing the number of epochs.
    \item \textbf{Advanced Architectures} \textemdash\ Alternative architectures could be experimented with, architectures such as EfficientNet, that may offer better performance. Furthermore, a larger transformer model could be used, such as \texttt{google/vit-base-patch16-224} from HuggingFace with sufficient hardware. This will likely outperform the CNNs, and emerge as the most performant model.
    \item \textbf{Rigorous Testing} \textemdash\ More rigorous testing could be performed by having radiologists review the results, and provide feedback on the model's performance. This will help to identify areas for improvement, and ensure that the model is clinically relevant. This could also be aided by the use of Grad-CAM to visualise the model's predictions, and understand its decision-making process.
	\item \textbf{Data Augmentation} \textemdash\ tf.image operations like random flips, rotations, and brightness adjustments could be introduced to improve generalisation for CNNs.
	\item \textbf{User Interface} \textemdash\ A user-friendly interface can be developed to allow users to easily upload images, and view results.
	\item \textbf{Deployment} \textemdash\ The model can be deployed as a web service through REST APIs, and be inferenced through them for user-friendly accessibility, particularly for clinical settings.
	\item \textbf{CI/CD} \textemdash\ Implementing continuous integration, and continuous deployment (CI/CD) practices such as the introduction of containerisation with Docker will ensure that the system is easily maintainable, scalable, and transferable between different platforms.
\end{itemize}

\end{document}
